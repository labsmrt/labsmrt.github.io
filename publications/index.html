<!doctype html><html dir=ltr lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><title>Publications - SMRT Lab</title><meta content="Browse our publications." name=description><link href="/css/main.css?=v1.0.0" rel=preload as=style><meta content=summary_large_image name=twitter:card><meta content="Publications - SMRT Lab" name=twitter:title><meta content="Browse our publications." name=twitter:description><meta content=https://labsmrt.github.io//images/preview.png name=twitter:image><meta content="Publications - SMRT Lab" name=og:title><meta content="Browse our publications." name=og:description><meta content=website property=og:type><meta content=https://labsmrt.github.io//publications/ property=og:url><meta content=https://labsmrt.github.io//images/preview.png property=og:image><meta content=image/png property=og:image:type><meta content=1200 property=og:image:width><meta content=630 property=og:image:height><link href=https://labsmrt.github.io//publications/ rel=canonical><link href=https://labsmrt.github.io//feed.xml rel=alternate title="" type=application/rss+xml><meta content="Eleventy v1.0.1" name=generator><meta content=#6001ff name=theme-color><meta content="SMRT Lab" name=apple-mobile-web-app-title><meta content="SMRT Lab" name=application-name><meta content=#6001ff name=msapplication-TileColor><link href=/favicon.ico rel=icon><link href="/css/main.css?=v1.0.0" rel=stylesheet><style>#blog-grid{--cols-size:400px}</style><script defer src="/js/main.js?=v1.0.0"></script></head><body class="flex flex-col min-h-screen"><a href=#page-main class=skip-link>Go to main content</a><header class="page-header sticky top-0"><div class="flex items-center justify-between container md-py-4 py-2"><a href=/ class="flex-shrink logo"><img alt="SMRT Lab" height=50 src=/images/logo.jpg width=50></a><div class="flex items-center"><nav class="hidden sm-block"><ul class="flex-wrap -row menu"><li><a href=/research/ >Research</a></li><li><a href=/team/ >Team</a></li><li><a href=/collaboration/ >Collaboration</a></li><li><a href=/publications/ class=is-active aria-current=page>Publications</a></li><li><a href=/teng/ >Dr. Teng</a></li><li><a href=/life/ >Life</a></li></ul></nav><button class="-icon btn ms-4 sm-hidden" type=button id=show-offcanvas-menu><svg fill=currentColor height=24 width=24><title>Open menu</title><use href=/images/sprite.svg#menu /></svg></button></div></div></header><dialog class="offcanvas-end px-2 py-0" id=offcanvas-menu><div class="flex items-center justify-between px-3 py-3"><a href=/ class="flex-shrink logo"><img alt="SMRT Lab" height=50 src=/images/logo.jpg width=50> </a><button class="-icon btn close" type=button><svg fill=currentColor height=24 width=24><title>Close menu</title><use href=/images/sprite.svg#close /></svg></button></div><div class="dialog-inner flex-auto"><nav class=menu aria-label="Offcanvas menu"><li><a href=/research/ >Research</a></li><li><a href=/team/ >Team</a></li><li><a href=/collaboration/ >Collaboration</a></li><li><a href=/publications/ class=is-active aria-current=page>Publications</a></li><li><a href=/teng/ >Dr. Teng</a></li><li><a href=/life/ >Life</a></li></nav></div></dialog><main class="flex-grow page-container" id=page-main><div class=container></div><div style="background-color:var(--color-theme); color:white; text-align:center;"><p class=h1 style="padding-top: 30px;">Publications</p><p style="padding-bottom: 35px;">Browse our publications.</p></div><article class="container my-6"><p>* Lab trainees.</p><h2>2022</h2><p>Chang, A., Teng, X., Assaneo, F., &amp; Poeppel, D. (2022). Amplitude modulation perceptually distinguishes music and speech. <em>PsyArXiv</em>. <a href=https://psyarxiv.com/juzrh/ class=external target=_blank rel="noopener noreferrer">Preprint</a></p><p>Chen, X., Teng, X., Chen, H., Pan, Y., Geyer, P. (2022) Toward reliable signal decoding for electroencephalogram: A benchmark study to EEGNeX. <em>ArXiv</em>. <a href=https://arxiv.org/abs/2207.12369 class=external target=_blank rel="noopener noreferrer">Preprint</a></p><h2>2021</h2><p>Teng, X., &amp; Zhang, R-Y. (2021) Sequential Temporal Anticipation Characterized by Neural Power Modulation and in Recurrent Neural Network. <em>bioRxiv</em>. <a href=https://www.biorxiv.org/content/10.1101/2021.10.04.463033v1 class=external target=_blank rel="noopener noreferrer">Preprint</a></p><p>Teng, X., Larrouy-Maestri, P., Poeppel, D. Segmenting and Predicting Musical Phrase Structure Exploits Neural Gain Modulation and Phase Precession. <em>bioRxiv</em>. <a href=https://www.biorxiv.org/content/10.1101/2021.07.15.452556v1 class=external target=_blank rel="noopener noreferrer">Preprint</a></p><h2>2020</h2><p>Teng, X., Meng, Q., &amp; Poeppel, D. (2020). Modulation Spectra Capture EEG Responses to Speech Signals and Drive Distinct Temporal Response Functions. Eneuro, ENEURO.0399–20.2020. <strong>- 1/f Modulation Spectra Part 2</strong> <a href=https://www.eneuro.org/content/8/1/ENEURO.0399-20.2020 class=external target=_blank rel="noopener noreferrer">PDF</a> | <a href=https://osf.io/yp4k3/ class=external target=_blank rel="noopener noreferrer">OSF</a></p><p>Teng, X., Ma, M., Yang, J., Blohm, S., Cai, Q., &amp; Tian, X. (2020). Constrained Structure of Ancient Chinese Poetry Facilitates Speech Content Grouping. <em>Current Biology</em>. <a href=https://ray306.github.io/neural_poem/ class=external target=_blank rel="noopener noreferrer">Demo</a> | <a href=https://osf.io/jg3xh/ class=external target=_blank rel="noopener noreferrer">OSF</a> | <a href=http://doi.org/10.1016/j.cub.2020.01.059 class=external target=_blank rel="noopener noreferrer">See more</a></p><p>Poeppel, D., &amp; Teng, X. (2020). 2.06 - Entrainment in Human Auditory Cortex: Mechanism and Functions. In B. Fritzsch (Ed.), The Senses: A Comprehensive Reference (Second Edition) (pp. 63–76). Oxford: Elsevier. <a href=https://www.sciencedirect.com/science/article/pii/B978012805408600018X?via%3Dihub class=external target=_blank rel="noopener noreferrer">See more</a></p><p>Shrestha M, Teng X, Lee S, Noeth U, Poeppel D, Deichmann R (2020). Functional MRI of the Auditory Cortex: Comparison of Different Sequences to investigate Speech and Amplitude Modulated Sounds. In: Proceedings of the 28th annual meeting of ISMRM. <a href=https://www.researchgate.net/publication/343432053_Functional_MRI_of_the_Auditory_Cortex_Comparison_of_Different_Sequences_to_investigate_Speech_and_Amplitude_Modulated_Sounds class=external target=_blank rel="noopener noreferrer">See more</a></p><h2>2019</h2><p>Teng, X., &amp; Poeppel, D. (2019). Theta and Gamma Bands Encode Acoustic Dynamics over Wide-ranging Timescales. <em>Cerebral Cortex</em>. <a href=https://www.biorxiv.org/content/10.1101/547125v1 class=external target=_blank rel="noopener noreferrer">Preprint</a> | <a href=https://academic.oup.com/cercor/article/30/4/2600/5637582 class=external target=_blank rel="noopener noreferrer">See more</a></p><p>Teng, X., Cogan, G. B., &amp; Poeppel, D. (2019). Speech fine structure contains critical temporal cues to support speech segmentation. NeuroImage, 116152. <a href=https://www.sciencedirect.com/science/article/abs/pii/S1053811919307438?via%3Dihub class=external target=_blank rel="noopener noreferrer">Preprint</a> | <a href=http://doi.org/10.1016/j.neuroimage.2019.116152 class=external target=_blank rel="noopener noreferrer">See more</a></p><p>Kong F, Wang X, Teng X, Zheng N, Yu G, Meng Q (2019). Reverberant speech recognition with actual cochlear implants: verifying a pulsatile vocoder simulation method. In: Proceedings of the 23rd International Congress on Acoustics. <a href=https://www.researchgate.net/publication/339442284_Reverberant_speech_recognition_with_actual_cochlear_implants_verifying_a_pulsatile_vocoder_simulation_method class=external target=_blank rel="noopener noreferrer">See more</a></p><p>Teng, X., Poeppel, D. (2019) Experimental evidence on computational mechanisms of concurrent temporal channels for auditory processing, <em>Cognitive Computational Neuroscience 2019</em>. <a href=https://www.researchgate.net/publication/335434716_Experimental_evidence_on_computational_mechanisms_of_concurrent_temporal_channels_for_auditory_processing class=external target=_blank rel="noopener noreferrer">See more</a></p><h2>2018</h2><p>Tian, X., Ding, N., Teng, X., Bai, F., &amp; Poeppel, D. (2018). Imagined speech influences perceived loudness of sound. <em>Nature Human Behaviour, 2</em>(3), 225. <a href=https://www.researchgate.net/publication/323266425_Imagined_speech_influences_perceived_loudness_of_sound class=external target=_blank rel="noopener noreferrer">See more</a></p><p>Teng, X., Sun, Y., &amp; Poeppel, D. (2018). Temporal order judgment reveals local-global auditory processes. <em>Acta Acustica united with Acustica, 104</em>(5), 817-820. <a href=https://www.researchgate.net/profile/Xiangbin-Teng/publication/328219170_Temporal_Order_Judgment_Reveals_Local-Global_Auditory_Processes/links/5bc0bd3b458515a7a9e3222b/Temporal-Order-Judgment-Reveals-Local-Global-Auditory-Processes.pdf class=external target=_blank rel="noopener noreferrer">PDF</a></p><p>Teng, X., Tian, X., Doelling, K., &amp; Poeppel, D. (2018). Theta band oscillations reflect more than entrainment: behavioral and neural evidence demonstrates an active chunking process. <em>European Journal of Neuroscience, 48</em>(8), 2770-2782. <strong>- 1/f Modulation Spectra Part 1</strong> <a href=https://www.researchgate.net/profile/Xiangbin-Teng/publication/320454937_Theta_band_oscillations_reflect_more_than_entrainment_Behavioral_and_neural_evidence_demonstrates_an_active_chunking_process/links/59ede6494585158fe53411b5/Theta-band-oscillations-reflect-more-than-entrainment-Behavioral-and-neural-evidence-demonstrates-an-active-chunking-process.pdf class=external target=_blank rel="noopener noreferrer">PDF</a></p><h2>2017</h2><p>Teng, X., Tian, X., Rowland, J., &amp; Poeppel, D. (2017). Concurrent temporal channels for auditory processing: Oscillatory neural entrainment reveals segregation of function at different scales. <em>PLoS biology, 15</em>(11), e2000812. <a href="https://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.2000812&amp;type=printable" class=external target=_blank rel="noopener noreferrer">PDF</a></p><h2>2016</h2><p>Teng, X., Tian, X., &amp; Poeppel, D. (2016). Testing multi-scale processing in the auditory system. <em>Scientific reports, 6</em>, 34390. <a href=https://www.nature.com/articles/srep34390.pdf class=external target=_blank rel="noopener noreferrer">PDF</a></p><h2>2012</h2><p>Wu, M., Li, H., Gao, Y., Lei, M., Teng, X., Wu, X., &amp; Li, L. (2012). Adding irrelevant information to the content prime reduces the prime-induced unmasking effect on speech recognition. <em>Hearing research, 283</em>(1-2), 136-143. <a href=https://www.researchgate.net/publication/51815262_Adding_irrelevant_information_to_the_content_prime_reduces_the_prime-induced_unmasking_effect_on_speech_recognition class=external target=_blank rel="noopener noreferrer">See more</a></p></article></main><footer class="mt-8 page-footer"><div class="container auto-grid"><nav><p class=h5>Contact</p>Department of Psychology<br>The Chinese University of Hong Kong<br>Shatin, N.T.<br>Hong Kong SAR<p></p><div class="flex flex-wrap mx-n2 socials"><a href=mailto:labteng@gmail.com class=social-icon target=_blank title=mail><svg fill=currentColor height=24 width=24><title>mail</title><use href=/images/socials.svg#mail></use></svg> &nbsp </a><a href=https://github.com/labsmrt class=social-icon target=_blank title=github><svg fill=currentColor height=24 width=24><title>github</title><use href=/images/socials.svg#github></use></svg> &nbsp</a></div><p></p></nav><div></div><div></div><div class="h1 weight-bold" style=display:flex;align-items:center;justify-content:center;>SMRT Lab</div><small class=copyright>©2022 SMRT Lab. All Rights Reserved.</small></div></footer></body></html>