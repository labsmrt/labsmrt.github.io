<!doctype html><html dir=ltr lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><title>語言韻律研究參與者招募 - SMRT Lab</title><meta content="Understand how human beings understand speech and appreciate music." name=description><link href="/css/main.css?=v1.0.0" rel=preload as=style><meta content=summary_large_image name=twitter:card><meta content="語言韻律研究參與者招募 - SMRT Lab" name=twitter:title><meta content="Understand how human beings understand speech and appreciate music." name=twitter:description><meta content=https://labsmrt.github.io//images/preview.jpg name=twitter:image><meta content="語言韻律研究參與者招募 - SMRT Lab" name=og:title><meta content="Understand how human beings understand speech and appreciate music." name=og:description><meta content=website property=og:type><meta content=https://labsmrt.github.io//participant/prosody/ property=og:url><meta content=https://labsmrt.github.io//images/preview.jpg property=og:image><meta content=image/png property=og:image:type><meta content=1200 property=og:image:width><meta content=630 property=og:image:height><link href=https://labsmrt.github.io//participant/prosody/ rel=canonical><link href=https://labsmrt.github.io//feed.xml rel=alternate title="" type=application/rss+xml><meta content="Eleventy v1.0.1" name=generator><meta content=#6001ff name=theme-color><meta content="SMRT Lab" name=apple-mobile-web-app-title><meta content="SMRT Lab" name=application-name><meta content=#6001ff name=msapplication-TileColor><link href=/favicon.ico rel=icon><link href="/css/main.css?=v1.0.0" rel=stylesheet><style>.recruitments-layout{--container-size:84ch;--container-padding-y:3rem}time{color:var(--color-text-muted)}</style><script defer src="/js/main.js?=v1.0.0"></script></head><body class="flex flex-col min-h-screen"><a href=#page-main class=skip-link>Go to main content</a><header class="page-header sticky top-0"><div class="flex items-center justify-between container md-py-4 py-2"><a href=/ class="flex-shrink logo"><img src=/images/logo.jpg width=50 alt="SMRT Lab" height=50></a><div class="flex items-center"><nav class="hidden sm-block"><ul class="flex-wrap -row menu"><li><a href=/research/ >Research</a></li><li><a href=/team/ >Team</a></li><li><a href=/collaboration/ >Collaboration</a></li><li><a href=/publications/ >Publications</a></li><li><a href=/life/ >Life</a></li><li><a href=/Participant/ >Participant</a></li><li><a href=/methodologies/ >Methodologies</a></li></ul></nav><button class="-icon btn ms-4 sm-hidden" type=button id=show-offcanvas-menu><svg fill=currentColor height=24 width=24><title>Open menu</title><use href=/images/sprite.svg#menu /></svg></button></div></div></header><dialog class="offcanvas-end px-2 py-0" id=offcanvas-menu><div class="flex items-center justify-between px-3 py-3"><a href=/ class="flex-shrink logo"><img src=/images/logo.jpg width=50 alt="SMRT Lab" height=50> </a><button class="-icon btn close" type=button><svg fill=currentColor height=24 width=24><title>Close menu</title><use href=/images/sprite.svg#close /></svg></button></div><div class="dialog-inner flex-auto"><nav class=menu aria-label="Offcanvas menu"><li><a href=/research/ >Research</a></li><li><a href=/team/ >Team</a></li><li><a href=/collaboration/ >Collaboration</a></li><li><a href=/publications/ >Publications</a></li><li><a href=/life/ >Life</a></li><li><a href=/Participant/ >Participant</a></li><li><a href=/methodologies/ >Methodologies</a></li></nav></div></dialog><main class="flex-grow page-container" id=page-main><div class=container><nav aria-label=breadcrumb><span class=aria-only>You are here:</span><ol class=breadcrumbs itemscope itemtype=https://schema.org/BreadcrumbList><li itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=/participant/ itemprop=item><span itemprop=name>Participant</span><meta content=1 itemprop=position></a></li><li itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a href=/participant/prosody/ itemprop=item aria-current=page><span itemprop=name>語言韻律研究參與者招募</span><meta content=2 itemprop=position></a></li></ol></nav></div><article class="container my-6 recruitments-layout"><div class="mb-8 md-mb-10"><h1 class=my-0>語言韻律研究參與者招募</h1></div><p style=text-align:center><img src=/images/prosody1.jpg width=60%></p><p>誠邀您參與我們與香港理工大學中文及雙語學系合作進行的臨床學術研究，本研究是關於言語韻律處理的腦電圖（EEG）研究，研究對像是以漢語為母語的18-35歲的成年人。</p><p>研究目的：這項研究旨在了解語言處理過程中的神經機制，我們的目標是通過操縱顯示給您的語言刺激來找到時間切分和預測處理的神經證據。 正式實驗共分為三個部分，我們會為您帶上入耳式耳機，您將會在螢幕上看到一些文字，透過耳機聽到一些語句，並根據每小節任務做出行為反應。您對本研究的參與完全出於自願。 您可以隨時退出參與而不會產生任何不良影響，在這種情況下，您的研究補償將根據您的參與時間按比例發放。</p><p>實驗時長：實驗將持續約 2 小時。</p><p>參與條件：</p><p>1） 年齡18-35歲；</p><p>2） 聽力正常；</p><p>3） 母語為漢語（包括國語、廣東話）。</p><p>實驗流程：</p><p>1）本項實驗將使用 EEG（腦電圖）記錄您的神經反應；</p><p>2）您將透過入耳式耳機聽到語音片段，並透過按鍵做出行為反應；</p><p>3）實驗結束後，我們會提供熱水、洗髮水、毛巾和吹風機供您洗頭。</p><p>若您有興趣參與本項實驗，請透過以下連結或掃描海報二維碼報名</p><p>國語母語者報名連結： https://forms.gle/txauUx3WmdKZiZRP9</p><p>香港廣東話母語者報名連結： https://forms.gle/7hGLR9NEdQt1EYmz5</p><p>問詢：jinghanyang@cuhk.edu.hk</p><hr class=mt-12><nav class=pagination><a href=/participant/TBC/ class=ms-auto>Next: 更多實驗上線中</a></nav></article></main><footer class="mt-8 page-footer"><div class="container auto-grid"><nav><p class=h5>Contact</p>Department of Psychology<br>The Chinese University of Hong Kong<br>Shatin, N.T.<br>Hong Kong SAR<p></p><div class="flex flex-wrap mx-n2 socials"><a href=mailto:labteng@gmail.com class=social-icon target=_blank title=mail><svg fill=currentColor height=24 width=24><title>mail</title><use href=/images/socials.svg#mail></use></svg> &nbsp </a><a href=https://github.com/labsmrt class=social-icon target=_blank title=github><svg fill=currentColor height=24 width=24><title>github</title><use href=/images/socials.svg#github></use></svg> &nbsp</a></div><p></p></nav><div></div><div></div><div class="h1 weight-bold" style=display:flex;align-items:center;justify-content:center;>SMRT Lab</div><small class=copyright>©2022 SMRT Lab. All Rights Reserved.</small></div></footer></body></html>