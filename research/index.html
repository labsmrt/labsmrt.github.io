<!doctype html><html dir=ltr lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><title>Research - SMRT Lab</title><meta content="See what&amp;#39;s happening." name=description><link href="/css/main.css?=v1.0.0" rel=preload as=style><meta content=summary_large_image name=twitter:card><meta content="Research - SMRT Lab" name=twitter:title><meta content="See what&amp;#39;s happening." name=twitter:description><meta content=https://labsmrt.github.io//images/preview.jpg name=twitter:image><meta content="Research - SMRT Lab" name=og:title><meta content="See what&amp;#39;s happening." name=og:description><meta content=website property=og:type><meta content=https://labsmrt.github.io//research/ property=og:url><meta content=https://labsmrt.github.io//images/preview.jpg property=og:image><meta content=image/png property=og:image:type><meta content=1200 property=og:image:width><meta content=630 property=og:image:height><link href=https://labsmrt.github.io//research/ rel=canonical><link href=https://labsmrt.github.io//feed.xml rel=alternate title="" type=application/rss+xml><meta content="Eleventy v1.0.1" name=generator><meta content=#6001ff name=theme-color><meta content="SMRT Lab" name=apple-mobile-web-app-title><meta content="SMRT Lab" name=application-name><meta content=#6001ff name=msapplication-TileColor><link href=/favicon.ico rel=icon><link href="/css/main.css?=v1.0.0" rel=stylesheet><style>#blog-grid{--cols-size:400px}</style><script defer src="/js/main.js?=v1.0.0"></script></head><body class="flex flex-col min-h-screen"><a href=#page-main class=skip-link>Go to main content</a><header class="page-header sticky top-0"><div class="flex items-center justify-between container md-py-4 py-2"><a href=/ class="flex-shrink logo"><img alt="SMRT Lab" height=50 src=/images/logo.jpg width=50></a><div class="flex items-center"><nav class="hidden sm-block"><ul class="flex-wrap -row menu"><li><a href=/research/ class=is-active aria-current=page>Research</a></li><li><a href=/team/ >Team</a></li><li><a href=/collaboration/ >Collaboration</a></li><li><a href=/publications/ >Publications</a></li><li><a href=/teng/ >Dr. Teng</a></li><li><a href=/life/ >Life</a></li></ul></nav><button class="-icon btn ms-4 sm-hidden" type=button id=show-offcanvas-menu><svg fill=currentColor height=24 width=24><title>Open menu</title><use href=/images/sprite.svg#menu /></svg></button></div></div></header><dialog class="offcanvas-end px-2 py-0" id=offcanvas-menu><div class="flex items-center justify-between px-3 py-3"><a href=/ class="flex-shrink logo"><img alt="SMRT Lab" height=50 src=/images/logo.jpg width=50> </a><button class="-icon btn close" type=button><svg fill=currentColor height=24 width=24><title>Close menu</title><use href=/images/sprite.svg#close /></svg></button></div><div class="dialog-inner flex-auto"><nav class=menu aria-label="Offcanvas menu"><li><a href=/research/ class=is-active aria-current=page>Research</a></li><li><a href=/team/ >Team</a></li><li><a href=/collaboration/ >Collaboration</a></li><li><a href=/publications/ >Publications</a></li><li><a href=/teng/ >Dr. Teng</a></li><li><a href=/life/ >Life</a></li></nav></div></dialog><main class="flex-grow page-container" id=page-main><div class=container></div><div style="background-color:var(--color-theme); color:white; text-align:center;"><p class=h1 style="padding-top: 30px;">Research</p><p style="padding-bottom: 35px;">See what&#39;s happening.</p></div><article class="container my-6"><h2>Segmentation and Rhythms in Speech and Music</h2><p>Speech and music are auditory sequences composed of basic building blocks (e.g. notes or syllables) organized into hierarchical structures over multiple timescales (e.g. words and sentences, or beats and musical phrases)—and they unfold linearly in time. Extracting perceptually the building blocks from physical signals does not come for free: acoustic waveforms carrying speech and music are continuous, without clear boundaries marking syllables or chords (imagine, for example, if there were no spacing between words in written text). How does the brain segment the continuous speech and music streams into event segments? In our recent studies, we found that the brain relies on rhythmic structures and prior knowledge of temporal structures to segment continuous auditory streams into perceptual units for further processing.</p><h2>Prior Knowledge and Prediction</h2><p>We always know some knowledge of temporal regularities in the world: when the sun will rise, when someone is going to finish her or his sentences, and when a melody starts and ends. How does the brain learn the temporal regularities and use such prior knowledge to predict the future? In a recent study, we found that listeners can learn statistical distributions of events in time and use such knowledge to predict future time points, which is underlied by neural power modulation and a phenomenon of phase precession.</p><h2>Where are Rhythms in the Brain and Artificial Systems</h2><p>Early sensory experience shapes how we perceive speech; Infants show sensitivity to their native speech rhythms very early. One explanation for infants developing native-language-specific tuning is that they have learned the statistical distribution of rhythm variations in their native language; the native speakers’ brain is crystalized for the statistical distribution of their native speech rhythms. Our question is: where are the rhythms stored and how does the brain use the prior knowledge of rhythms to make predictions? To answer this question, we conduct neuroimaging recording (e.g., EEG/MEG/fMRI) on people learning new L2 rhythms and temporal statistical distributions and, correspondingly, train neural network models to learn rhythms and temporal regularities. By probing the brain and dissecting the artificial system, we hope to reveal where and how the rhythms are stored.</p></article></main><footer class="mt-8 page-footer"><div class="container auto-grid"><nav><p class=h5>Contact</p>Department of Psychology<br>The Chinese University of Hong Kong<br>Shatin, N.T.<br>Hong Kong SAR<p></p><div class="flex flex-wrap mx-n2 socials"><a href=mailto:labteng@gmail.com class=social-icon target=_blank title=mail><svg fill=currentColor height=24 width=24><title>mail</title><use href=/images/socials.svg#mail></use></svg> &nbsp </a><a href=https://github.com/labsmrt class=social-icon target=_blank title=github><svg fill=currentColor height=24 width=24><title>github</title><use href=/images/socials.svg#github></use></svg> &nbsp</a></div><p></p></nav><div></div><div></div><div class="h1 weight-bold" style=display:flex;align-items:center;justify-content:center;>SMRT Lab</div><small class=copyright>©2022 SMRT Lab. All Rights Reserved.</small></div></footer></body></html>